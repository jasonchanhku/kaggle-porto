{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking Using Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score, roc_curve, auc\n",
    "\n",
    "# Modelling\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "\n",
    "# Data prep, logging, and garbage collection\n",
    "from load_data import load_train_data, load_test_data\n",
    "from logging import StreamHandler, DEBUG, Formatter, FileHandler, getLogger\n",
    "import gc\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-09 07:07:26,844 __main__ 17 [INFO][<module>] start \n",
      "2018-06-09 07:07:36,382 __main__ 28 [INFO][<module>] Train data prep completed (595212, 58) \n",
      "2018-06-09 07:07:50,871 __main__ 36 [INFO][<module>] Test data prep completed (892816, 58) \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIR = 'result_tmp/'\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "\n",
    "log_fmt = Formatter('%(asctime)s %(name)s %(lineno)d [%(levelname)s][%(funcName)s] %(message)s ')\n",
    "handler = StreamHandler()\n",
    "handler.setLevel('INFO')\n",
    "handler.setFormatter(log_fmt)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "handler = FileHandler(DIR + 'train.py.log', 'a')\n",
    "handler.setLevel(DEBUG)\n",
    "handler.setFormatter(log_fmt)\n",
    "logger.setLevel(DEBUG)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "logger.info('start')\n",
    "\n",
    "# data_prep\n",
    "df = load_train_data()\n",
    "x_train = df.drop(['target'], axis = 1)\n",
    "y_train = df['target']\n",
    "\n",
    "use_cols = x_train.columns.values\n",
    "\n",
    "logger.debug('train columns: {} {}'.format(use_cols.shape, use_cols))\n",
    "\n",
    "logger.info('Train data prep completed {}'.format(x_train.shape))\n",
    "\n",
    "del df\n",
    "gc.collect()\n",
    "\n",
    "df = load_test_data()\n",
    "\n",
    "x_test = df[use_cols].sort_values('id')\n",
    "logger.info('Test data prep completed {}'.format(x_test.shape))\n",
    "\n",
    "\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "* Assumes each baseline model has been tuned using some kind of method\n",
    "* The paramaters are the optimum ones already chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "        'seed': 0,\n",
    "        'colsample_bytree': 0.3085,\n",
    "        'silent': 1,\n",
    "        'subsample': 0.7,\n",
    "        'learning_rate': 0.01,\n",
    "        'objective': 'binary:logistic',\n",
    "        'max_depth': 5,\n",
    "        'num_parallel_tree': 1,\n",
    "        'min_child_weight': 4.2922,\n",
    "        'eval_metric': 'auc',\n",
    "        'eta':0.1,\n",
    "        'gamma': 0.5290,\n",
    "        'subsample':0.9930,\n",
    "        'max_delta_step':0,\n",
    "        'booster':'gbtree',\n",
    "        'scale_pos_weight': 26,\n",
    "        'n_estimators': 2000,\n",
    "        'n_jobs': -1\n",
    "}\n",
    "    \n",
    "\n",
    "model_xgb = xgb.XGBClassifier(**xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 0.3085,\n",
       " 'eta': 0.1,\n",
       " 'eval_metric': 'auc',\n",
       " 'gamma': 0.529,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 4.2922,\n",
       " 'missing': None,\n",
       " 'n_estimators': 2000,\n",
       " 'n_jobs': -1,\n",
       " 'nthread': None,\n",
       " 'num_parallel_tree': 1,\n",
       " 'objective': 'binary:logistic',\n",
       " 'random_state': 0,\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 26,\n",
       " 'seed': 0,\n",
       " 'silent': 1,\n",
       " 'subsample': 0.993}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {'C': 10, \n",
    "             'fit_intercept': True, \n",
    "             'penalty': 'l1', \n",
    "             'random_state': 0, \n",
    "             'verbose':2}\n",
    "\n",
    "model_lr = LogisticRegression(**lr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'ovr',\n",
       " 'n_jobs': 1,\n",
       " 'penalty': 'l1',\n",
       " 'random_state': 0,\n",
       " 'solver': 'liblinear',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 2,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'learning_rate': 0.024, \n",
    "    'max_depth': 5, \n",
    "    'boosting': 'gbdt', \n",
    "    'objective': 'binary', \n",
    "    'metric': 'auc',\n",
    "    'feature_fraction': .7,\n",
    "    'is_training_metric': False, \n",
    "    'seed': 99,\n",
    "    'n_estimators': 2000\n",
    "}\n",
    "\n",
    "model_lgb = lgb.LGBMClassifier(**lgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting': 'gbdt',\n",
       " 'boosting_type': 'gbdt',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'feature_fraction': 0.7,\n",
       " 'is_training_metric': False,\n",
       " 'learning_rate': 0.024,\n",
       " 'max_depth': 5,\n",
       " 'metric': 'auc',\n",
       " 'min_child_samples': 20,\n",
       " 'min_child_weight': 0.001,\n",
       " 'min_split_gain': 0.0,\n",
       " 'n_estimators': 2000,\n",
       " 'n_jobs': -1,\n",
       " 'num_leaves': 31,\n",
       " 'objective': 'binary',\n",
       " 'random_state': None,\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 0.0,\n",
       " 'seed': 99,\n",
       " 'silent': True,\n",
       " 'subsample': 1.0,\n",
       " 'subsample_for_bin': 200000,\n",
       " 'subsample_freq': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgb.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators=500, \n",
    "                                  max_depth=6, \n",
    "                                  criterion='entropy', \n",
    "                                  min_samples_split=10,  \n",
    "                                  n_jobs=-1, \n",
    "                                  random_state=123, \n",
    "                                  verbose=1, \n",
    "                                  class_weight = \"balanced\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': 'balanced',\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 6,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 10,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 500,\n",
       " 'n_jobs': -1,\n",
       " 'oob_score': False,\n",
       " 'random_state': 123,\n",
       " 'verbose': 1,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ROUNDS = 650\n",
    "OPTIMIZE_ROUNDS = False\n",
    "LEARNING_RATE = 0.05\n",
    "\n",
    "model_cat = CatBoostClassifier(\n",
    "    learning_rate=LEARNING_RATE, \n",
    "    depth=5, \n",
    "    l2_leaf_reg = 14, \n",
    "    iterations = MAX_ROUNDS,\n",
    "    verbose = False,\n",
    "    loss_function='Logloss',eval_metric='AUC'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': 5,\n",
       " 'eval_metric': 'AUC',\n",
       " 'iterations': 650,\n",
       " 'l2_leaf_reg': 14,\n",
       " 'learning_rate': 0.05,\n",
       " 'logging_level': 'Silent',\n",
       " 'loss_function': 'Logloss'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cat.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Models Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_cv(model):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    auc= cross_val_score(model, x_train.values, y_train.values, scoring=\"accuracy\", cv = skf)\n",
    "    return(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score ofCat Boost: 0.9635 (0.0000)\n",
      "Score ofXGBoost: 0.6748 (0.0016)\n",
      "Score ofLight GBM: 0.9636 (0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   28.6s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   29.2s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   29.7s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   28.8s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   29.1s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score ofRandom Forest: 0.6566 (0.0054)\n"
     ]
    }
   ],
   "source": [
    "# # For script purposes only\n",
    "\n",
    "models = ['Cat Boost', 'XGBoost', 'Light GBM', 'Random Forest']\n",
    "for n, i in enumerate([model_cat, model_xgb, model_lgb, model_rf]):\n",
    "    score = auc_cv(i)\n",
    "    print('Score of' + models[n] + ': {:.4f} ({:.4f})'.format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling\n",
    "Creating an sklearn helper class to reuse codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnHelper(object):\n",
    "    \n",
    "    def __init__(self, clf, seed=0):\n",
    "        self.clf = clf()\n",
    "        \n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train.values, y_train.values)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.predict(x)\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        return self.predict_proba(x)[:, 1]\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        return self.clf.fit(x.values, y.values)\n",
    "    \n",
    "    def feature_importance(self, x, y):\n",
    "        print(self.clf.fit(x, y).feature_importances_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out of Fold (OOF) Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful parameters which will come in handy later on\n",
    "ntrain = x_train.shape[0]\n",
    "ntest = x_test.shape[0]\n",
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "kf = KFold(n_splits= NFOLDS, random_state=SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros((ntrain, ) )\n",
    "    oof_test = np.zeros((ntest, ))\n",
    "    oof_test_kf = np.empty((NFOLDS, ntest))\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x_train, y_train)):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "        \n",
    "        clf.fit(x_tr, y_tr)\n",
    "        \n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_kf[i, :] = clf.predict(x_test)\n",
    "        \n",
    "    oof_test[:] = oof_test_kf.mean(axis =0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_oof_train, xgb_oof_test = get_oof(model_xgb, x_train.values, y_train.values, x_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_oof_train, lgb_oof_test = get_oof(model_lgb, x_train.values, y_train.values, x_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_oof_train, cat_oof_test = get_oof(model_cat, x_train.values, y_train.values, x_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   48.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:   13.4s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   50.3s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:   13.5s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   48.9s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:   13.2s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   48.3s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:   12.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   47.0s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:   11.3s finished\n"
     ]
    }
   ],
   "source": [
    "rf_oof_train, rf_oof_test = get_oof(model_rf, x_train.values, y_train.values, x_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    }
   ],
   "source": [
    "lr_oof_train, lr_oof_test = get_oof(model_lr, x_train.values, y_train.values, x_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_con = np.concatenate(( xgb_oof_train, lr_oof_train, cat_oof_train, rf_oof_train), axis=1)\n",
    "x_test_con = np.concatenate(( xgb_oof_test, lr_oof_test, cat_oof_test, rf_oof_test), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Level Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = xgb.XGBClassifier(\n",
    "    #learning_rate = 0.02,\n",
    " n_estimators= 2000,\n",
    " max_depth= 4,\n",
    " min_child_weight= 2,\n",
    " #gamma=1,\n",
    " gamma=0.9,                        \n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread= -1,\n",
    " scale_pos_weight=26).fit(x_train_con, y_train)\n",
    "predictions = gbm.predict(x_test_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = 'result_tmp/'\n",
    "submission = pd.DataFrame(\n",
    "\n",
    "    {'id': x_test['id'],\n",
    "     'target': predictions\n",
    "    }\n",
    ")\n",
    "\n",
    "submission.to_csv(DIR + 'submission_oof_stacked.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
